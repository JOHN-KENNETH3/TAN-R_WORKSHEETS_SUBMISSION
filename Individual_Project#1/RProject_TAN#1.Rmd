---
title: 'Individual Project  #1'
author: "John Kenneth D. Tan"
date: "2022-12-02"
output:
  html_document:
    df_print: paged
---
Course, Year & Section: BSIT 2-A


Libraries to be used/called out
```{r , library}
library(dplyr)
library(twitteR)
library(tm)
library(tidytext)
library(tidyr)
library(plotly)
library(rtweet)
library(RColorBrewer)
library(ggplot2)
library(slam)
library(wordcloud)
library(wordcloud2)
library(corpus)
```

1.Extract from twitter using your developer's credentials. 
Choose any keyword you want. 

Tokens and keys are needed. 
Check your Programs and Apps in the Developerâ€™s Portal.
```{r , keys}
CONSUMER_SECRET <-"bmUGeGVHxLxtc63GAyEHo2DDaHpmmjeJyrZ3XPLSMRtvOY8xpW"
CONSUMER_KEY <- "dxIq4p3oOGBD9DM4sfw2JVcFh"
ACCESS_SECRET <- "YkZLrUJVHrwCh44s92O70XaYmLZWCHvIDick1T60wdH5v"
ACCESS_TOKEN <- "1594143309362270210-hApMHAP6C8nRlj9ipxEfzrnLBbrWcJ"
```

Connect to twitter app
```{r , connect}
setup_twitter_oauth(consumer_key = CONSUMER_KEY,
                    consumer_secret = CONSUMER_SECRET,
                    access_token = ACCESS_TOKEN,
                    access_secret = ACCESS_SECRET)
```

2. Get 10000 observations "excluding retweets".
```{r , tweets}
Lisa_trendTwts = searchTwitter("Lalisa -filter:retweets",
                            n=10000,
                            since = "2022-11-20",
                            until = "2022-11-26",
                            lang = "en",
                            retryOnRateLimit = 120)

```
Convert data into dataframe
```{r , df}
Lisa_TweetsDF <- twListToDF(Lisa_trendTwts)
class(Lisa_TweetsDF)
names(Lisa_TweetsDF)
View(Lisa_TweetsDF)
head(Lisa_TweetsDF)[1:5]
head(Lisa_TweetsDF$text)[1:5]

save(Lisa_TweetsDF,file = "Lisa_trendingTweetsDF.Rdata")
load(file = "Lisa_trendingTweetsDF.Rdata")
```

Checking for missing values in a data frame
```{r , missing}
sapply(Lisa_TweetsDF, function(x) sum(is.na(x)))
```

Removes some (unicode?) values in text field
```{r , unicode}
Lisa_TweetsDF$text <- sapply(Lisa_TweetsDF$text,function(x) iconv(x,to='UTF-8'))
load(file = "Lisa_trendingTweetsDF.Rdata")
Lisa_TweetsDF$text <- sapply(Lisa_TweetsDF$text,function(x) iconv(enc2utf8(x), sub="byte"))
head(Lisa_TweetsDF$text)
```

Subsetting using the dplyr()package
```{r , subset}
Lalisa_dataDF <- Lisa_TweetsDF %>%
select(screenName,text,created,statusSource)
save(Lalisa_dataDF, file = "Lisa_trendingTweetsDF.Rdata")
```

Grouping the date created
```{r , grouping}
Lalisa_dataDF %>%  
  group_by(1) %>%  
  summarise(max = max(created), min = min(created))

Lalisa_dataDF %>% 
 mutate(Created_At_Round = created%>% 
          round(units = 'hours') %>% 
          as.POSIXct())

Lalisa_dataDF %>%  
  group_by(1) %>%  
  summarise(max = max(created), min = min(created))

Lalisa_dataDF %>% pull(created) %>% max()
```

3. Plot the time series from the date created. with legends.
```{r , ts}
ggplot(data = Lalisa_dataDF, aes(x = created), fill = Lalisa_dataDF) +
  geom_histogram(aes(fill = ..count..)) + 
  theme(legend.position="right",
        axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  xlab("Time") + ylab("Number of tweets") + 
  scale_fill_gradient(low = "midnightblue", high = "aquamarine4")
```

Trend Analysis using the source
```{r , trend_an}
encodeSource <- function(x) {
  if(grepl(">Twitter for iPhone</a>", x)){
    "iphone"
  }else if(grepl(">Twitter for iPad</a>", x)){
    "ipad"
  }else if(grepl(">Twitter for Android</a>", x)){
    "android"
  } else if(grepl(">Twitter Web Client</a>", x)){
    "Web"
  } else if(grepl(">Twitter for Windows Phone</a>", x)){
    "windows phone"
  }else if(grepl(">dlvr.it</a>", x)){
    "dlvr.it"
  }else if(grepl(">IFTTT</a>", x)){
    "ifttt"
  }else if(grepl(">Facebook</a>", x)){  
    "facebook"
  }else {
    "others"
  }
}
```
```{r , lisaDF}
Lalisa_dataDF$tweetSource = sapply(Lalisa_dataDF$statusSource, 
                              encodeSource)

tweet_appSource <- Lalisa_dataDF %>% 
  select(tweetSource) %>%
  group_by(tweetSource) %>%
  summarize(count=n()) %>%
  arrange(desc(count)) 

Source_subset <- subset(tweet_appSource,count >10)
```

Plot a graph (any graph you want)  based on the type of device - 
found in Source -that the user use. Include the legends. 
```{r , dataDf}
dataDF <- data.frame(
  category = tweet_appSource$tweetSource,
  count = tweet_appSource$count
)

dataDF$fraction = dataDF$count / sum(dataDF$count)
dataDF$percentage = dataDF$count / sum(dataDF$count) * 100
dataDF$ymax = cumsum(dataDF$fraction)
dataDF$ymin = c(0, head(dataDF$ymax, n=-1))
dataDF$roundP = round(dataDF$percentage, digits = 2)
```

```{r , plot}
 
 Source <- paste(dataDF$category, dataDF$roundP, "%")
 
 ggplot(dataDF, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=Source)) +
   geom_rect() +
   coord_polar(theta="y") + 
   xlim(c(2, 4)) +
   theme_void() +
   theme(legend.position = "right")
``` 
 
Using wordcloud() package but using a shape pentagon 
```{r , wordcloud} 
 tweet_appScreen <- Lalisa_dataDF %>%
   select(screenName) %>%
   group_by(screenName) %>%
   summarize(count=n()) %>%
   arrange(desc(count)) 
```

Convert to Corpus
```{r , corp_data}
 namesCorpus <- Corpus(VectorSource(Lalisa_dataDF$screenName))
``` 

Running the code using the wordcloud()
```{r , wordCloud}
 wordcloud2(data=tweet_appScreen, 
            size=0.8, 
            color='random-light',
            shape = 'pentagon')
```
 
 
